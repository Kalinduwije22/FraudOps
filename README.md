<div align="center">

  <img src="https://readme-typing-svg.demolab.com?font=Fira+Code&weight=700&size=32&duration=3000&pause=1000&color=00D4FF&center=true&vCenter=true&width=600&lines=ğŸ›¡ï¸+FraudOps;Real-Time+Fraud+Detection;End-to-End+MLOps+Pipeline" alt="Typing SVG" />

  <p><strong>A production-ready, end-to-end MLOps pipeline for real-time fraud detection â€” powered by PyTorch, MLflow, Kafka, Prefect, and Streamlit.</strong></p>

  <br/>

  <p>
    <a href="https://github.com/Kalinduwije22/FraudOps/stargazers">
      <img src="https://img.shields.io/github/stars/Kalinduwije22/FraudOps?style=for-the-badge&logo=github&color=FFD700&labelColor=0D1117" alt="Stars" />
    </a>
    <a href="https://github.com/Kalinduwije22/FraudOps/network/members">
      <img src="https://img.shields.io/github/forks/Kalinduwije22/FraudOps?style=for-the-badge&logo=github&color=FF8C00&labelColor=0D1117" alt="Forks" />
    </a>
    <a href="https://github.com/Kalinduwije22/FraudOps/issues">
      <img src="https://img.shields.io/github/issues/Kalinduwije22/FraudOps?style=for-the-badge&logo=github&color=FF4500&labelColor=0D1117" alt="Issues" />
    </a>
    <a href="https://github.com/Kalinduwije22/FraudOps/blob/main/LICENSE">
      <img src="https://img.shields.io/badge/License-MIT-22C55E?style=for-the-badge&logo=opensourceinitiative&logoColor=white&labelColor=0D1117" alt="License" />
    </a>
  </p>

  <p>
    <img src="https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python&logoColor=white&labelColor=0D1117" alt="Python" />
    <img src="https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white&labelColor=0D1117" alt="PyTorch" />
    <img src="https://img.shields.io/badge/MLflow-0194E2?style=for-the-badge&logo=mlflow&logoColor=white&labelColor=0D1117" alt="MLflow" />
    <img src="https://img.shields.io/badge/Apache_Kafka-231F20?style=for-the-badge&logo=apachekafka&logoColor=white&labelColor=0D1117" alt="Kafka" />
    <img src="https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white&labelColor=0D1117" alt="Streamlit" />
    <img src="https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white&labelColor=0D1117" alt="Docker" />
    <img src="https://img.shields.io/badge/Prefect-024DFD?style=for-the-badge&logo=prefect&logoColor=white&labelColor=0D1117" alt="Prefect" />
  </p>

  <br/>

  <p>
    <a href="#-overview">Overview</a> &nbsp;â€¢&nbsp;
    <a href="#-tech-stack">Tech Stack</a> &nbsp;â€¢&nbsp;
    <a href="#-repository-structure">Structure</a> &nbsp;â€¢&nbsp;
    <a href="#-ml-pipeline">ML Pipeline</a> &nbsp;â€¢&nbsp;
    <a href="#-getting-started">Getting Started</a> &nbsp;â€¢&nbsp;
    <a href="#-usage">Usage</a> &nbsp;â€¢&nbsp;
    <a href="#-contributing">Contributing</a>
  </p>

</div>

---

## ğŸ“– Overview

**FraudOps** is a comprehensive, production-ready **Machine Learning Operations (MLOps)** framework purpose-built for **real-time financial fraud detection**.

It goes far beyond a simple model training script â€” it is a **full lifecycle system** that automates everything from data generation and model training to live transaction streaming, experiment tracking, automated orchestration, and interactive web-based inference. Every component is modular, reproducible, and built with industry-standard tools.

> ğŸ¯ **Goal:** Detect fraudulent transactions in real time with a deep-learning model, while keeping every experiment fully reproducible and ready for production deployment.

---

## âœ¨ Features

<table>
  <tr>
    <td>ğŸ§  <strong>Deep Learning Model</strong></td>
    <td>Custom <code>FraudNet</code> neural network built with <strong>PyTorch</strong>, trained on class-imbalanced transaction data (95% legit / 5% fraud).</td>
  </tr>
  <tr>
    <td>ğŸ“ˆ <strong>Experiment Tracking</strong></td>
    <td><strong>MLflow</strong> logs every hyperparameter, loss curve, and model artifact automatically on every training run.</td>
  </tr>
  <tr>
    <td>âš¡ <strong>Real-Time Streaming</strong></td>
    <td><strong>Apache Kafka</strong> (via Docker) powers a live transaction stream. A producer generates fake transactions; the model consumes and scores them instantly.</td>
  </tr>
  <tr>
    <td>ğŸ”„ <strong>Pipeline Orchestration</strong></td>
    <td><strong>Prefect</strong> automates the training workflow as a managed flow with a visual dashboard.</td>
  </tr>
  <tr>
    <td>ğŸŒ <strong>Interactive Web Dashboard</strong></td>
    <td><strong>Streamlit</strong> web app for model inference â€” submit transaction features and get fraud predictions live.</td>
  </tr>
  <tr>
    <td>âš™ï¸ <strong>Config-Driven</strong></td>
    <td>All model hyperparameters, data settings, and Kafka config live in <code>config/config.yaml</code> â€” no code changes needed to experiment.</td>
  </tr>
  <tr>
    <td>ğŸ³ <strong>Dockerized Infrastructure</strong></td>
    <td>Kafka & Zookeeper spin up with a single <code>make infra-up</code> command. No manual setup required.</td>
  </tr>
  <tr>
    <td>ğŸ› ï¸ <strong>Makefile Automation</strong></td>
    <td>Every workflow step â€” setup, train, stream, predict, deploy â€” is a single <code>make</code> command away.</td>
  </tr>
</table>

---

## ğŸ”§ Tech Stack

| Layer | Technology | Purpose |
|---|---|---|
| **Model** | PyTorch | Neural network training & inference |
| **Tracking** | MLflow | Experiment logging & model registry |
| **Streaming** | Apache Kafka | Real-time transaction data pipeline |
| **Orchestration** | Prefect | Automated training workflow |
| **Web UI** | Streamlit | Interactive prediction dashboard |
| **Infrastructure** | Docker & Docker Compose | Kafka + Zookeeper environment |
| **Config** | YAML | Centralized hyperparameter management |
| **Automation** | GNU Make | One-command pipeline execution |

---

## ğŸ“‚ Repository Structure

```
FraudOps/
â”‚
â”œâ”€â”€ ğŸ“ artifacts/               # ğŸ’¾ Trained model weights & scalers (fraud_model.pth)
â”œâ”€â”€ ğŸ“ config/
â”‚   â””â”€â”€ config.yaml             # âš™ï¸  All hyperparameters, data config, Kafka settings
â”‚
â”œâ”€â”€ ğŸ“ mlruns/                  # ğŸ“Š MLflow experiment run history
â”œâ”€â”€ mlflow.db                   # ğŸ—„ï¸  SQLite backend for MLflow tracking
â”‚
â”œâ”€â”€ ğŸ“ src/                     # ğŸ§© Core ML modules
â”‚   â”œâ”€â”€ dataset.py              #    PyTorch Dataset wrapper
â”‚   â”œâ”€â”€ model.py                #    FraudNet neural network definition
â”‚   â”œâ”€â”€ train.py                #    Full training pipeline with MLflow logging
â”‚   â”œâ”€â”€ inference.py            #    Kafka consumer + real-time predictor
â”‚   â”œâ”€â”€ producer.py             #    Kafka transaction stream producer
â”‚   â”œâ”€â”€ orchestrate.py          #    Prefect flow definition
â”‚   â””â”€â”€ utils.py                #    Shared utilities (config loader)
â”‚
â”œâ”€â”€ ğŸ“ web/
â”‚   â””â”€â”€ app.py                  # ğŸŒ Streamlit web dashboard for predictions
â”‚
â”œâ”€â”€ main.py                     # ğŸš€ Unified CLI entry point (train/stream/predict/web)
â”œâ”€â”€ Makefile                    # ğŸ› ï¸  All automation commands
â”œâ”€â”€ .gitignore
â””â”€â”€ .large_files.txt            # ğŸ“¦ References to large tracked files
```

---

## ğŸ”¬ ML Pipeline

```mermaid
flowchart LR
    A[âš™ï¸ config.yaml] --> B[ğŸ“Š Data Generation\nSklearn make_classification\n20K samples Â· 15 features]
    B --> C[ğŸ§  FraudNet Training\nPyTorch Â· BCE Loss\nAdam Â· 50 Epochs]
    C --> D[ğŸ“ˆ MLflow Tracking\nParams Â· Loss Â· Model Artifact]
    D --> E[ğŸ’¾ artifacts/\nfraud_model.pth]
    E --> F{Choose Mode}
    F -->|predict| G[âš¡ Kafka Stream\nReal-time scoring]
    F -->|web| H[ğŸŒ Streamlit\nInteractive Dashboard]
```

### Model Architecture â€” `FraudNet`

The core model is a **Feed-Forward Neural Network** (`FraudNet`) trained to classify transactions as fraudulent or legitimate:

```
Input (15 features)
      â†“
  Linear(15 â†’ 64)  +  ReLU
      â†“
  Linear(64 â†’ 1)   +  Sigmoid
      â†“
Output (fraud probability: 0.0 â€“ 1.0)
```

**Training Configuration** (from `config.yaml`):

| Parameter | Value |
|---|---|
| Samples | 20,000 (95% legit / 5% fraud) |
| Features | 15 |
| Hidden Dim | 64 |
| Learning Rate | 0.001 |
| Batch Size | 64 |
| Epochs | 50 |
| Loss Function | Binary Cross-Entropy |
| Optimizer | Adam |

---

## ğŸš€ Getting Started

### ğŸ› ï¸ Prerequisites

Ensure you have the following installed:

| Tool | Version | Notes |
|---|---|---|
| Python | 3.8+ | Recommended: 3.10 |
| Docker Desktop | Latest | Required for Kafka streaming |
| GNU Make | Any | Pre-installed on Linux/macOS. Windows: [GnuWin32](http://gnuwin32.sourceforge.net/packages/make.htm) |
| Git | Any | For cloning the repo |
| CUDA *(optional)* | 12.1 | For GPU-accelerated training |

### ğŸ“¥ Installation

**1. Clone the repository**

```bash
git clone https://github.com/Kalinduwije22/FraudOps.git
cd FraudOps
```

**2. Set up the virtual environment and install all dependencies**

```bash
make setup
```

> This creates a `fraud_env/` virtual environment and installs: `torch`, `mlflow`, `kafka-python-ng`, `streamlit`, `scikit-learn`, `prefect`, `pyyaml`, and `pandas`.

**3. (For Kafka streaming) Start the infrastructure**

```bash
make infra-up
```

> This uses Docker Compose to spin up **Kafka** and **Zookeeper** locally on `localhost:29092`.

---

## ğŸ’» Usage

All commands are available through the `Makefile`. Here is the full workflow:

### 1. ğŸ§  Train the Model

Runs the end-to-end training pipeline: generates data, trains `FraudNet`, logs everything to MLflow, and saves the model.

```bash
make train
# or
python main.py train
```

### 2. ğŸ“Š View Experiment Dashboard (MLflow)

Visualize all training runs, compare metrics, and download model artifacts.

```bash
mlflow ui --backend-store-uri sqlite:///mlflow.db
```

> Open your browser at **http://127.0.0.1:5000**

### 3. âš¡ Start Real-Time Transaction Stream (Kafka)

Requires `make infra-up` to be running. Opens a producer that generates synthetic fraud transactions and sends them to the Kafka topic `transaction_stream`.

```bash
make stream
# or
python main.py stream
```

### 4. ğŸ” Start the Real-Time Predictor

Consumes the Kafka stream and prints live fraud predictions to the terminal.

```bash
make predict
# or
python main.py predict
```

### 5. ğŸŒ Launch the Web Dashboard (Streamlit)

Serves the Streamlit web app where you can manually input transaction features and get instant fraud predictions.

```bash
make web
# or
python main.py web
```

> Open your browser at **http://localhost:8501**

### 6. ğŸ”„ Run as an Orchestrated Flow (Prefect)

Runs the training pipeline as a Prefect managed flow for automated, scheduled execution.

```bash
make flow
```

To view the Prefect orchestration dashboard:

```bash
make flow-ui
```

### 7. ğŸ§¹ Clean Up

Removes all `__pycache__` directories and `.pyc` files.

```bash
make clean
```

### âš¡ Quick Reference

| Command | Action |
|---|---|
| `make setup` | Create venv & install dependencies |
| `make infra-up` | Start Kafka + Zookeeper (Docker) |
| `make infra-down` | Stop Docker containers |
| `make train` | Train the PyTorch model |
| `make stream` | Start Kafka transaction producer |
| `make predict` | Start real-time Kafka consumer/predictor |
| `make web` | Launch Streamlit web dashboard |
| `make flow` | Run automated Prefect training flow |
| `make flow-ui` | Start Prefect dashboard server |
| `make clean` | Remove cache files |

---

## âš™ï¸ Configuration

All pipeline parameters are controlled from a single file â€” **`config/config.yaml`**:

```yaml
project:
  name: "Fraud_Detection_System"
  experiment_name: "Pytorch_Fraud_Experiment_v1"

data:
  num_samples: 20000       # Total training samples
  num_features: 15         # Input feature count
  test_size: 0.2           # 80/20 train/test split
  save_path: "artifacts/"  # Where models are saved

model:
  input_dim: 15
  hidden_dim: 64
  output_dim: 1
  learning_rate: 0.001
  epochs: 50
  batch_size: 64

kafka:
  bootstrap_servers: "localhost:29092"
  topic_input: "transaction_stream"
  group_id: "fraud_detector_group"
```

---

## ğŸ¤ Contributing

Contributions make the open-source community an amazing place to learn, inspire, and create. **Any contribution is greatly appreciated!**

1. ğŸ´ **Fork** the repository
2. ğŸŒ¿ **Create** your feature branch
   ```bash
   git checkout -b feature/AmazingFeature
   ```
3. ğŸ’¾ **Commit** your changes
   ```bash
   git commit -m "feat: Add some AmazingFeature"
   ```
4. ğŸš€ **Push** to the branch
   ```bash
   git push origin feature/AmazingFeature
   ```
5. ğŸ“¬ **Open a Pull Request** and describe your changes

### ğŸ’¡ Ideas for Contributions

- [ ] Add model evaluation metrics (F1, AUC-ROC, Precision, Recall)
- [ ] Integrate a real-world fraud dataset (e.g., IEEE-CIS, Kaggle credit card fraud)
- [ ] Add Docker container for the full application
- [ ] Implement model versioning and A/B testing with MLflow Model Registry
- [ ] Add CI/CD pipeline with GitHub Actions
- [ ] Extend the Streamlit dashboard with charts and history

---

## ğŸ“œ License

Distributed under the **MIT License**. See [`LICENSE`](LICENSE) for more information.

---

<div align="center">

  <h3>â­ If you find this project useful, please consider giving it a star!</h3>
  <p>It helps others discover this project and motivates further development.</p>

  <br/>

  <a href="https://github.com/Kalinduwije22/FraudOps/stargazers">
    <img src="https://img.shields.io/github/stars/Kalinduwije22/FraudOps?style=for-the-badge&logo=github&color=FFD700&labelColor=0D1117" alt="Stars" />
  </a>

  <br/><br/>

  <p>Built with â¤ï¸ by <a href="https://github.com/Kalinduwije22"><strong>Kalinduwije22</strong></a></p>

  <img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=6,11,20&height=100&section=footer" alt="footer" />

</div>